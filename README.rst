Description
===========

The queue node is a server which handles requests from the queue client defined
in swarm (``swarm.queue.QueueClient``). One or more nodes make up a complete
queue, though only the client has this knowledge -- individual nodes know
nothing of each others' existence.

Data in the queue node is stored in memory, in fixed-sized, pre-allocated
buffers, one per data channel.

Deployment
==========

Upstart
-------

The queue node is configured to use upstart and will start automatically upon
server reboot. The upstart scripts are located in ``etc/init/queue.conf``.

Manually
--------

To manually start the queue node on a server, run ``sudo service queue start``.
This will start the screen session and the application. If the application/
screen session are already running, you'll need to shut them down first before
restarting.

Separate Queues
---------------

Currently, there are several completely separate queues which handle different
types of data:

* Tracking queue handling loglines generated by sonar.
* User-matching queue handling usermap records generated by sonar.
* Bidding queue handling bid records generated by thruster.
* Admedia queue handling admedia generated by shore.

To make matters more complicated, this separation is not consistent. The user-
matching records are, for instance, written to the same queue as the tracking
records.

There is no real reason for this separation by data type. The queue itself has
no knowledge about the data it's storing so, given a queue system with
sufficient memory, all data channels could be stored in a single queue system.

Single Nodes
------------

Due to current technical limitations (specifically relating to the handling of
PushMulti and ProduceMulti requests), each of the aforementioned queues consists
of just a single node.

Screen
------

The queue node runs as root in a screen session. The name of the session varies
on different servers to reflect the type of data stored in the node: on most
servers the screen session is named "queue" but on others it may be named
"admedia_queue".

Processes
---------

There should be a directory in ``/srv/queue`` for each instance of the queue
node, like ``/srv/queue/tracking``. Each directory should contain a
``queuenode`` binary and a ``versions`` folder, containing older binaries
(dated).

Design
======

The structure of the queue node's code is based very closely around the
structure of the ``core.node`` package of swarm.

The basic components are:

Select Listener
  The ``swarm.core.node.model.Node : NodeBase`` class, which forms the
  foundation of all swarm nodes, owns an instance of
  ``ocean.net.server.SelectListener : SelectListener``. This provides the basic
  functionality of a server; that is, a listening socket which will accept
  incoming client connections. Each client connection is assigned to a
  connection handler instance from a pool.

Connection Handler Pool
  The select listener manages a pool of connection handlers (derived from
  ``swarm.core.node.connection.ConnectionHandler : ConnectionHandlerTemplate``.
  Each is associated with an incoming socket connection from a client. The
  connection handler reads a request code from the socket and then passes the
  request on to a request handler instance, which is constructed at scope (i.e.
  only exists for the lifetime of the request).

Request Handlers
  A handler class exists for each type of request which the node can handle.
  These are derived from ``swarm.core.node.request.model.IRequest : IRequest``.
  The request handler performs all communication with the client which is
  required by the protocol for the given request. This usually involves
  interacting with the node's storage channels.

Storage Channels
  The ``swarm.core.node.storage.model.IStorageChannels : IStorageChannelsTemplate``
  class provides the base for a set of storage channels, where each channel is
  conceived as storing a different type of data in the system. The individual
  storage channels are derived from
  ``swarm.core.node.storage.model.IStorageEngine : IStorageEngine``.

Monitoring
==========

Graphing
--------

TODO: Graphitus dashboard.

Resource Usage
--------------

A queue node process typically uses up to about 60% CPU usage (depending on
traffic), and a large chunk of RAM -- the config file defines the amount of
memory which is allocated for each channel stored, so the memory usage should be
in the region of <num channels * channel size>.

Checking Everything's OK
------------------------

Console Output
..............

The queue node displays some basic statistics on the console: its memory usage,
the number of open connections and handled records, the number of records and
bytes stored, and the fullness (as a percentage) of each channel.

Log Files
.........

The queue node writes two log files:

``root.log``
  Notification of errors when handling requests.

``stats.log``
  Statistics about the number of records and bytes stored (globally and per
  channel), the number of bytes sent and received over the network, and the
  number of open connections and records handled.

Possible Problems
-----------------

Crash
.....

Many applications in the system rely on being able to read and/or write to the
queue. There is, as previously mentioned, at present generally only a single
queue node running for each type of data, so this queue node going down would be
a very bad thing. Requests sent from client applications will simply be lost.
There is currently no fall-back mechanism, beyond the possibility for the client
applications themselves to cache and retry failed requests.

If a queue node crashes, it can simply be restarted.

Design
======

See section on overall design of the swarm nodes.

Data Flow
=========

Queue nodes do not access any other data stores.

Dependencies
============

:Dependency: liblzo2

.. _`server layout pages`: https://github.com/sociomantic/backend/wiki/Servers#wiki-server-layout
